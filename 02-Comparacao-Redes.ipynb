{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 02 - Comparação de Redes Neurais Rasas\n",
    "\n",
    "Aluno: Frederico Luis de Azevedo\n",
    "\n",
    "Professor: Dr. Francisco de Assis Boldt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas e Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificadores Utilizados\n",
    "\n",
    "A comparação das redes neurais será feita utilizados os seguintes classificadores\n",
    "- SVM com Kernel linear\n",
    "- SGD com função de perda 'hinge' (SMV Linear com descida de gradiente em seu treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "sgd = SGDClassifier(loss='hinge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    ('SGD',sgd),\n",
    "    ('SVM',svm)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases de dados\n",
    "\n",
    "Para este exercício serão construídas as seguintes bases de dados binárias:\n",
    "- Base 1: 500 registros com 20 características, balanceada.\n",
    "- Base 2: 500 registros com 20 características, desbalanceada\n",
    "- Base 3: 500 registros com 5 características, balanceada.\n",
    "- Base 4: 500 registros com 5 características, desbalanceada\n",
    "- Base 5: 10.000 registros com 20 características, balanceada.\n",
    "- Base 6: 10.000 registros com 20 características, desbalanceada\n",
    "- Base 7: 10.000 registros com 5 características, balanceada.\n",
    "- Base 8: 10.000 registros com 5 características, desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('Base 1', Bunch(n_samples=500, n_features=20, weights=[0.5, 0.5])),\n",
    "    ('Base 2', Bunch(n_samples=500, n_features=20, weights=[0.1, 0.9])),\n",
    "    ('Base 3', Bunch(n_samples=500, n_features=5, weights=[0.5, 0.5])),\n",
    "    ('Base 4', Bunch(n_samples=500, n_features=5, weights=[0.1, 0.9])),\n",
    "    ('Base 5', Bunch(n_samples=10000, n_features=20, weights=[0.5, 0.5])),\n",
    "    ('Base 6', Bunch(n_samples=10000, n_features=20, weights=[0.1, 0.9])),\n",
    "    ('Base 7', Bunch(n_samples=10000, n_features=5, weights=[0.5, 0.5])),\n",
    "    ('Base 8', Bunch(n_samples=10000, n_features=5, weights=[0.1, 0.9]))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação de Performance\n",
    "\n",
    "A avaliação da performance das redes neurais será feita com uma versão modificada da classe PerformanceEvaluator criada na disciplina de Reconhecimento de Padrões.\n",
    "\n",
    "A modificação foi feita para que a classe possa criar uma base de dados dinamicamente com base nos parâmetros: tamanho da base, quantidade de caracterísitcas e balanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceEvaluator():\n",
    "  def __init__(self, datasets, cross_val = False):\n",
    "    self.datasets = datasets\n",
    "    self.cross_val = cross_val\n",
    "  def score(self, clf, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test)\n",
    "  def evaluate(self, clfs):\n",
    "    for name, dataset in self.datasets:\n",
    "        print('-------- {} --------'.format(name))\n",
    "        print(' ')\n",
    "        \n",
    "        X, y = make_classification(n_samples=dataset.n_samples, n_features=dataset.n_features, weights=dataset.weights)\n",
    "        \n",
    "        #unique, counts = np.unique(y, return_counts=True)\n",
    "        #print(dict(zip(unique, counts)))\n",
    "        #print(X.shape)\n",
    "        \n",
    "        print('{:>25}: {}'.format('Samples', dataset.n_samples))\n",
    "        print('{:>25}: {}'.format('Features', dataset.n_features))\n",
    "        if (dataset.weights[1:] == dataset.weights[:-1]):\n",
    "            print('{:>25}: {}'.format('Balanced', 'true'))\n",
    "        else:\n",
    "            print('{:>25}: {}'.format('Balanced', 'false'))\n",
    "        \n",
    "        print(' ')\n",
    "        print('{:>25}'.format('---- eval ---'))\n",
    "        print(' ')\n",
    "        \n",
    "        for clf_name, clf in clfs:\n",
    "            start_time = time.time()\n",
    "            if (self.cross_val):\n",
    "                scores = cross_val_score(clf, X, y, cv=5)\n",
    "                print('{:>25}: {}'.format(clf_name, scores))\n",
    "                #print('{:>25}: {}'.format('Mean', scores.mean()))\n",
    "                #print('{:>25}: {}'.format('Std Deviation', scores.std()))\n",
    "                #print('{:>25}: {}'.format('Median', np.median(scores)))\n",
    "                print('{:>25}: {}'.format('Best', scores.max()))\n",
    "            else:\n",
    "                print('{:>25}: {}'.format(clf_name, self.score(clf, X, y)))\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('{:>25}: {}'.format('Time Spent', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))\n",
    "            print(' ')\n",
    "       \n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Base 1 --------\n",
      " \n",
      "                  Samples: 500\n",
      "                 Features: 20\n",
      "                 Balanced: true\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.91089109 0.93       0.9        0.95       0.91919192]\n",
      "                     Best: 0.95\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.92079208 0.94       0.93       0.94       0.93939394]\n",
      "                     Best: 0.94\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      " \n",
      "-------- Base 2 --------\n",
      " \n",
      "                  Samples: 500\n",
      "                 Features: 20\n",
      "                 Balanced: false\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.89108911 0.88118812 0.88       0.88888889 0.8989899 ]\n",
      "                     Best: 0.898989898989899\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.89108911 0.94059406 0.94       0.88888889 0.92929293]\n",
      "                     Best: 0.9405940594059405\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      " \n",
      "-------- Base 3 --------\n",
      " \n",
      "                  Samples: 500\n",
      "                 Features: 5\n",
      "                 Balanced: true\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.93069307 0.95       0.93       0.92       0.87878788]\n",
      "                     Best: 0.95\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.93069307 0.98       0.93       0.93       0.90909091]\n",
      "                     Best: 0.98\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      " \n",
      "-------- Base 4 --------\n",
      " \n",
      "                  Samples: 500\n",
      "                 Features: 5\n",
      "                 Balanced: false\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.98019802 0.96       0.97       0.96       0.91919192]\n",
      "                     Best: 0.9801980198019802\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.99009901 0.96       0.97       0.97       0.97979798]\n",
      "                     Best: 0.9900990099009901\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      " \n",
      "-------- Base 5 --------\n",
      " \n",
      "                  Samples: 10000\n",
      "                 Features: 20\n",
      "                 Balanced: true\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.95552224 0.9435     0.95       0.952      0.94297149]\n",
      "                     Best: 0.9555222388805598\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.95602199 0.9535     0.958      0.9555     0.94997499]\n",
      "                     Best: 0.958\n",
      "               Time Spent: 00:00:03\n",
      " \n",
      " \n",
      "-------- Base 6 --------\n",
      " \n",
      "                  Samples: 10000\n",
      "                 Features: 20\n",
      "                 Balanced: false\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.93303348 0.9395     0.9335     0.933      0.93096548]\n",
      "                     Best: 0.9395\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.93753123 0.9465     0.941      0.9445     0.93396698]\n",
      "                     Best: 0.9465\n",
      "               Time Spent: 00:00:04\n",
      " \n",
      " \n",
      "-------- Base 7 --------\n",
      " \n",
      "                  Samples: 10000\n",
      "                 Features: 5\n",
      "                 Balanced: true\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.92103948 0.91704148 0.9225     0.93246623 0.93396698]\n",
      "                     Best: 0.9339669834917459\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.93253373 0.92753623 0.936      0.93746873 0.93846923]\n",
      "                     Best: 0.9384692346173087\n",
      "               Time Spent: 00:00:02\n",
      " \n",
      " \n",
      "-------- Base 8 --------\n",
      " \n",
      "                  Samples: 10000\n",
      "                 Features: 5\n",
      "                 Balanced: false\n",
      " \n",
      "            ---- eval ---\n",
      " \n",
      "                      SGD: [0.96751624 0.96051974 0.974      0.97648824 0.97148574]\n",
      "                     Best: 0.976488244122061\n",
      "               Time Spent: 00:00:00\n",
      " \n",
      "                      SVM: [0.96951524 0.97101449 0.975      0.97598799 0.97398699]\n",
      "                     Best: 0.9759879939969985\n",
      "               Time Spent: 00:00:01\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "pe = PerformanceEvaluator(datasets, cross_val = True)\n",
    "pe.evaluate(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "É possível observar nas bases menores, com 500 registros, que o SVM performa melhor independente da quantidade de características e do balanceamento. Apenas caso da Base 1 (500 registros, 20 características, balanceada) que o SGD performou melhor que o SVM mas por pouco. Em todo caso, é possível observar nos valores do cross_validation que os scores do SGD são mais esparsos. Caberia um teste para testar se mais folds ajudariam na performance do SGD.\n",
    "\n",
    "Nas bases maiores, de 10.000 registros, ambos os classificadores performam com valores praticamente iguais sendo o melhor deles na última base (Base 8), com menos características e desbalanceada. Ou seja, a quantidade maior de registros, mesmo que aleatórios, fazem as duas redes ficarem com performances iguais entre si.\n",
    "\n",
    "O melhor score para 500 registros também está na base com menos características e desbalanceada (Base 4), assim como na base de 10.000 registros está na Base 8, mostrando que uma configuração de menos características e desbalanceada é a melhor configuração para estas redes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
